{
    "gaudi1": {
        "databricks/databricks-dolly-15k": {
            "num_train_epochs": 1,
            "eval_batch_size": 2,
            "distribution": {
                "single_card": {
                    "learning_rate": 2e-4,
                    "train_batch_size": 2,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 1",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio 0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm 0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.1",
                        "--lora_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--validation_split_percentage 20",
                        "--attn_softmax_bf16",
                        "--max_steps 100",
                        "--input_column_name context",
                        "--output_column_name response"
                    ]
                }
            }
        },
        "tatsu-lab/alpaca": {
            "num_train_epochs": 1,
            "eval_batch_size": 2,
            "distribution": {
                "multi_card": {
                    "learning_rate": 1e-4,
                    "train_batch_size": 2,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 4",
                        "--save_strategy no",
                        "--use_hpu_graphs_for_inference",
                        "--dataset_concatenation",
                        "--validation_split_percentage 10",
                        "--max_steps 100",
                        "--attn_softmax_bf16"
                    ]
                }
            }
        }
    },
    "gaudi2": {
        "databricks/databricks-dolly-15k": {
            "num_train_epochs": 1,
            "eval_batch_size": 8,
            "distribution": {
                "single_card": {
                    "learning_rate": 2e-4,
                    "train_batch_size": 16,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 1",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio 0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm 0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.1",
                        "--lora_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--validation_split_percentage 20",
                        "--attn_softmax_bf16",
                        "--max_steps 100",
                        "--input_column_name context",
                        "--output_column_name response"
                    ]
                }
            }
        },
        "tatsu-lab/alpaca": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16"
                    ]
                }
            }
        },
        "mamamiya405/finred": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16"
                    ]
                }
            }
        },
        "tatsu-lab/alpaca_fsdpcompile": {
            "num_train_epochs": 1,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16 True",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16",
                        "--pipelining_fwd_bwd False",
                        "--fsdp auto_wrap",
                        "--torch_compile_backend hpu_backend",
                        "--torch_compile",
                        "--fsdp_config examples/language-modeling/fsdp_config.json"
                    ]
                }
            }
        },
        "llama-adapter": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16",
                        "--adapter_layers 2",
                        "--adapter_len 4",
                        "--peft_type llama-adapter"
                    ]
                }
            }
        },
        "trl-sft": {
            "num_train_epochs": 1,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 1e-4,
                    "train_batch_size": 4,
                    "metrics": ["train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16 True",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--lora_r 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--max_seq_length 1024",
                        "--optim paged_adamw_32bit",
                        "--weight_decay 0.05",
                        "--report_to none",
                        "--max_steps 100"
                    ]
                }
            }
        },
        "trl-dpo": {
            "num_train_epochs": 1,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 5e-4,
                    "train_batch_size": 1,
                    "metrics": ["train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--logging_steps 1",
                        "--lora_r 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj k_proj out_proj fc_in fc_out wte",
                        "--max_length 1024",
                        "--max_prompt_length 512",
                        "--report_to none",
                        "--max_steps 100",
                        "--eval_steps 200",
                        "--lr_scheduler_type cosine",
                        "--warmup_steps 0",
                        "--weight_decay 0.05",
                        "--optimizer_type paged_adamw_32bit",
                        "--beta 0.1",
                        "--gradient_accumulation_steps 4",
                        "--sanity_check"
                    ]
                }
            }
        },
        "trl-reward": {
            "num_train_epochs": 1,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 5e-4,
                    "train_batch_size": 1,
                    "metrics": ["train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--logging_steps 1",
                        "--lora_r 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj k_proj out_proj fc_in fc_out wte",
                        "--max_length 1024",
                        "--eval_steps 200",
                        "--lr_scheduler_type cosine",
                        "--weight_decay 0.05",
                        "--gradient_accumulation_steps 4",
                        "--train_subset 500",
                        "--eval_subset 100"
                    ]
                }
            }
        },
        "trl-ppo": {
            "num_train_epochs": 1,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 5e-4,
                    "train_batch_size": 8,
                    "metrics": ["train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--lora_r 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--reward_model_name HuggingFaceH4/tiny-random-LlamaForSequenceClassification",
                        "--lora_target_modules q_proj v_proj k_proj out_proj fc_in fc_out wte",
                        "--max_train_samples 1000",
                        "--use_habana",
                        "--ppo_epochs 1",
                        "--batched_gen True",
                        "--mini_batch_size 1",
                        "--output_max_length 128",
                        "--input_max_length 128",
                        "--learning_rate 1.4e-5",
                        "--early_stopping"
                    ]
                }
            }
        },
        "prompt-tuning": {
            "num_train_epochs": 20,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 5e-4,
                    "train_batch_size": 1,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--num_virtual_tokens 8",
                        "--max_seq_length 64",
                        "--logging_steps 1",
                        "--report_to none",
                        "--max_steps 100",
                        "--peft_type prompt_tuning",
                        "--lr_scheduler_type cosine",
                        "--warmup_steps 0",
                        "--weight_decay 0.05",
                        "--gradient_accumulation_steps 1"
                    ]
                }
            }
        },
        "prefix-tuning": {
            "num_train_epochs": 20,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 5e-4,
                    "train_batch_size": 1,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--num_virtual_tokens 8",
                        "--max_seq_length 64",
                        "--logging_steps 1",
                        "--report_to none",
                        "--max_steps 100",
                        "--peft_type prefix_tuning",
                        "--lr_scheduler_type cosine",
                        "--warmup_steps 0",
                        "--weight_decay 0.05",
                        "--gradient_accumulation_steps 1"
                    ]
                }
            }
        },
        "p-tuning": {
            "num_train_epochs": 20,
            "eval_batch_size": 1,
            "distribution": {
                "multi_card": {
                    "learning_rate": 5e-4,
                    "train_batch_size": 1,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--num_virtual_tokens 8",
                        "--max_seq_length 64",
                        "--logging_steps 1",
                        "--report_to none",
                        "--max_steps 100",
                        "--peft_type p_tuning",
                        "--lr_scheduler_type cosine",
                        "--warmup_steps 0",
                        "--weight_decay 0.05",
                        "--gradient_accumulation_steps 1"
                    ]
                }
            }
        },
        "tatsu-lab/alpaca_fp8": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 16,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 1",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--logging_steps 40",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--pipelining_fwd_bwd",
                        "--throughput_warmup_steps 18",
                        "--use_lazy_mode",
                        "--max_grad_norm 0.3",
                        "--fp8"
                    ]
                }
            }
        },
        "ia3": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--ia3_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16",
                        "--peft_type ia3"
                    ]
                }
            }
        },
        "adalora": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--adalora_init_r 12",
                        "--adalora_target_r 4",
                        "--adalora_tinit 50",
                        "--adalora_tfinal 500",
                        "--adalora_delta_t 100",
                        "--adalora_orth_reg_weight 0.5",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16",
                        "--peft_type adalora"
                    ]
                }
            }
        },
        "vera": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 1e-2,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 1",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--vera_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16",
                        "--peft_type vera"
                    ]
                }
            }
        },
        "ln_tuning": {
            "num_train_epochs": 3,
            "eval_batch_size": 4,
            "distribution": {
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16",
                        "--gradient_accumulation_steps 2",
                        "--eval_strategy no",
                        "--save_strategy no",
                        "--warmup_ratio  0.03",
                        "--lr_scheduler_type constant",
                        "--max_grad_norm  0.3",
                        "--logging_steps 1",
                        "--use_hpu_graphs_for_inference",
                        "--ln_target_module input_layernorm post_attention_layernorm norm",
                        "--dataset_concatenation",
                        "--max_seq_length 512",
                        "--low_cpu_mem_usage True",
                        "--adam_epsilon 1e-08",
                        "--ddp_bucket_cap_mb 50",
                        "--validation_split_percentage 10",
                        "--attn_softmax_bf16",
                        "--peft_type ln_tuning"
                    ]
                }
            }
        },
        "tatsu-lab/alpaca_cp": {
            "num_train_epochs": 1,
            "eval_batch_size": 4,
            "distribution": {
                "deepspeed": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 8,
                    "metrics": ["perplexity", "train_runtime", "train_samples_per_second"],
                    "extra_arguments": [
                        "--bf16 True",
                        "--gradient_accumulation_steps 4",
                        "--logging_steps 1",
                        "--validation_split_percentage 10",
                        "--lora_rank 8",
                        "--lora_alpha 16",
                        "--lora_dropout 0.05",
                        "--lora_target_modules q_proj v_proj",
                        "--dataset_concatenation",
                        "--max_seq_length 2048",
                        "--pipelining_fwd_bwd",
                        "--throughput_warmup_steps 3",
                        "--use_lazy_mode",
                        "--context_parallel_size 4",
                        "--deepspeed tests/configs/deepspeed_zero_1.json"
                    ]
                }
            }
        }
    }
}
