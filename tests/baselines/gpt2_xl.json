{
    "wikitext": {
        "num_train_epochs": 2,
        "eval_batch_size": 2,
        "distribution": {
            "deepspeed": {
                "learning_rate": 5e-5,
                "train_batch_size": 8,
                "perplexity": 13.7992,
                "train_runtime": 469.2313,
                "extra_arguments": [
                    "--dataset_config_name wikitext-2-raw-v1",
                    "--gradient_accumulation 8",
                    "--gradient_checkpointing",
                    "--deepspeed tests/configs/deepspeed_zero_2.json"
                ]
            }
        }
    }
}