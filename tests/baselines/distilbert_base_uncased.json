{
    "gaudi": {
        "squad": {
            "num_train_epochs": 1,
            "eval_batch_size": 8,
            "distribution": {
                "single_card": {
                    "learning_rate": 1e-4,
                    "train_batch_size": 48,
                    "eval_f1": 84.5384,
                    "train_runtime": 264.3669,
                    "train_samples_per_second": 344.126,
                    "extra_arguments": [
                        "--max_seq_length 384",
                        "--use_hpu_graphs_for_inference"
                    ]
                },
                "multi_card": {
                    "learning_rate": 4e-4,
                    "train_batch_size": 48,
                    "eval_f1": 83.0667,
                    "train_runtime": 54.5344,
                    "train_samples_per_second": 2503.657,
                    "extra_arguments": [
                        "--max_seq_length 384",
                        "--use_hpu_graphs_for_inference"
                    ]
                }
            }
        }
    },
    "gaudi2": {
        "squad": {
            "num_train_epochs": 2,
            "eval_batch_size": 8,
            "distribution": {
                "single_card": {
                    "learning_rate": 2e-4,
                    "train_batch_size": 64,
                    "eval_f1": 84.5418,
                    "train_runtime": 117.8054,
                    "train_samples_per_second": 1547.185,
                    "extra_arguments": [
                        "--max_seq_length 384",
                        "--use_hpu_graphs_for_inference"
                    ]
                },
                "multi_card": {
                    "learning_rate": 3e-4,
                    "train_batch_size": 64,
                    "eval_f1": 83.2233,
                    "train_runtime": 24.0441,
                    "train_samples_per_second": 11144.651,
                    "extra_arguments": [
                        "--max_seq_length 384",
                        "--use_hpu_graphs_for_inference"
                    ]
                }
            }
        }
    }
}